{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한글 손글씨 분류 어플리케이션을 위한 Keras 모델 생성\n",
    "## Hand Written Korean Classification Application and Keras Model\n",
    "### with Keras, Tensorflow, CoreML, iOS\n",
    "\n",
    "1. 한글 손글씨 이미지 데이터 호출 및 데이터 전처리\n",
    "2. Keras 모델 생성 및 훈련\n",
    "3. CoreML 모델로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OcCLOY06BQiS"
   },
   "source": [
    "## Part1. 한글 손글씨 이미지 데이터 호출 및 전처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2Xq00MqPBcfL",
    "outputId": "347f6ac2-e892-48fb-b854-3a28b48d2c9f"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'labels-map.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6e7804e9e20e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlable_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"980_common_character.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcsv_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mlabels_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlable_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'labels-map.csv'"
     ]
    }
   ],
   "source": [
    "## 1-1. csv 파일에서 이미지 경로와 해당 이미지의 label 불러오기\n",
    "## 1-1. Importing a image path and the image's label from csv file\n",
    "\n",
    "import pandas as pd\n",
    "import io \n",
    "\n",
    "csv_file_path = \"labels-map.csv\"\n",
    "lable_file = \"980_common_character.txt\"\n",
    "\n",
    "csv_file = io.open(csv_file_path, 'r', encoding='utf-8')\n",
    "labels_file = io.open(lable_file, 'r', encoding='utf-8').read().splitlines()\n",
    "\n",
    "# Map characters to indices.\n",
    "label_dict = {}\n",
    "count = 0\n",
    "for label in labels_file:\n",
    "    label_dict[label] = count\n",
    "    count += 1\n",
    "\n",
    "# Build the lists.\n",
    "filenames = []\n",
    "labels = []\n",
    "\n",
    "for row in csv_file:\n",
    "    path, label = row.strip().split(',')\n",
    "    filenames.append(path)\n",
    "    labels.append(label_dict[label])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1-2. 두 개 리스트 랜덤으로 섞기\n",
    "## 1-2. Shuffle two lists randomly\n",
    "\n",
    "from subprocess import check_output\n",
    "import random\n",
    "\n",
    "seed = 999\n",
    "\n",
    "shuffled_indices = list(range(len(filenames)))\n",
    "random.seed(seed)\n",
    "random.shuffle(shuffled_indices)\n",
    "image_paths = [filenames[i] for i in shuffled_indices]\n",
    "labels = [labels[i] for i in shuffled_indices]\n",
    "print(\"csv finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1987
    },
    "colab_type": "code",
    "id": "bvanXF6rNbki",
    "outputId": "dedb828b-9876-43a9-a219-c9cfa0e94a86"
   },
   "outputs": [],
   "source": [
    "# Visualizing the data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "\n",
    "for i in range(1, 20):\n",
    "    img = mpimg.imread(image_paths[i])\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.imshow(img, cmap ='gray')\n",
    "    \n",
    "    print(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1547
    },
    "colab_type": "code",
    "id": "06jrcdcJBhAk",
    "outputId": "9eb74025-8618-4b89-dec9-56681379be15"
   },
   "outputs": [],
   "source": [
    "## 이미지 파일로 이미지를 불러와서 어레이에 담는다\n",
    "\n",
    "X_data = []\n",
    "\n",
    "total_count = 0\n",
    "prev_count = 0\n",
    "  \n",
    "for image_path in image_paths:\n",
    "    image = cv2.imread(image_path)\n",
    "    X_data.append(image)\n",
    "    total_count += 1\n",
    "    \n",
    "    if total_count - prev_count > 5000:\n",
    "      prev_count = total_count\n",
    "      print('{} images added...'.format(total_count))\n",
    "    \n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "WrDaqHPHBxNs",
    "outputId": "9c6fa52a-1307-4e79-ec33-1cad7a08a15d"
   },
   "outputs": [],
   "source": [
    "## 테스트셋/훈련셋 나누기\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(X_data)\n",
    "y = np.array(labels)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "print(\"\\nX_train:\")\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"\\nX_val\")\n",
    "print(X_val.shape)\n",
    "\n",
    "print(\"\\ny_train\")\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"\\ny_val\")\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 9200
    },
    "colab_type": "code",
    "id": "fX3Iv-sdLnWo",
    "outputId": "bed4d193-d83e-4b00-b8d4-7e2e8c00ca5b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "import keras\n",
    "import keras.utils as utils\n",
    "\n",
    "MODEL_SAVE_FOLDER_PATH = \"./model/\"\n",
    "model_path = MODEL_SAVE_FOLDER_PATH + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "    os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 500\n",
    "num_classes = 980\n",
    "\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_val = utils.to_categorical(y_val, num_classes)\n",
    "\n",
    "cb_checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1./255, \n",
    "                                     rotation_range=15, \n",
    "                                     width_shift_range=0.10, \n",
    "                                     height_shift_range=0.10, \n",
    "                                     shear_range=0.3, \n",
    "                                     zoom_range=[0.8, 1.2])\n",
    "\n",
    "val_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data_flow = train_generator.flow(X_train, y_train, \n",
    "                                       batch_size=batch_size)\n",
    "val_data_flow = val_generator.flow(X_val, y_val,\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "img_rows, img_cols = 32, 32\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(516, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "hist = model.fit_generator(train_data_flow,\n",
    "                           epochs=epochs,\n",
    "                           verbose=1,\n",
    "                           steps_per_epoch = 282,\n",
    "                           validation_data=val_data_flow,\n",
    "                           validation_steps = 70,\n",
    "                           callbacks=[cb_checkpoint])\n",
    "\n",
    "score = model.evaluate(X_val, y_val, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('hangul.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kCHTcnFRTz92"
   },
   "outputs": [],
   "source": [
    "# 5. 모델 학습 과정 표시하기\n",
    "\n",
    "acc = hist.history['acc']\n",
    "val_acc = hist.history['val_acc']\n",
    "loss = hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = []\n",
    "newimage = cv2.imread('./image-data/IMG_4543.png')\n",
    "test_x.append(newimage)\n",
    "\n",
    "testx = np.array(test_x)\n",
    "testx = testx / 255\n",
    "\n",
    "print(model.predict_classes(testx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
